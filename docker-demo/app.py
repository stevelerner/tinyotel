"""
Demo Frontend Application
Uses OpenTelemetry auto-instrumentation for traces, metrics, and logs
Includes automatic traffic generation for continuous telemetry
"""
import random
import time
import logging
import json
import requests
import threading
import os
from flask import Flask, jsonify
from opentelemetry import metrics

# Configure structured JSON logging
logging.basicConfig(
    level=logging.INFO,
    format='%(message)s'  # Just the message, structured logging will handle the rest
)
logger = logging.getLogger(__name__)

# Helper for structured logging
def log_json(level, message, **kwargs):
    """Log a structured JSON message"""
    log_data = {
        'message': message,
        **kwargs
    }
    getattr(logger, level)(json.dumps(log_data))

# Get the meter from the global provider (set up by auto-instrumentation)
# Don't create a new MeterProvider - use the one from opentelemetry-instrument
meter = metrics.get_meter(__name__)

# Create custom metrics
# Counter: Tracks cumulative values (always increasing)
order_counter = meter.create_counter(
    name="frontend.orders.total",
    description="Total number of orders processed",
    unit="orders"
)

request_counter = meter.create_counter(
    name="frontend.requests.total",
    description="Total number of requests by endpoint",
    unit="requests"
)

error_counter = meter.create_counter(
    name="frontend.errors.total",
    description="Total number of errors",
    unit="errors"
)

# Histogram: Records distribution of values
response_time_histogram = meter.create_histogram(
    name="frontend.response.duration",
    description="Response time distribution",
    unit="ms"
)

order_value_histogram = meter.create_histogram(
    name="frontend.order.value",
    description="Order value distribution",
    unit="dollars"
)

# UpDownCounter: Can go up and down (for gauges)
active_requests = meter.create_up_down_counter(
    name="frontend.requests.active",
    description="Number of active requests",
    unit="requests"
)

# Observable Gauge: Reports current value at collection time
def get_queue_size():
    """Simulated queue size"""
    return [metrics.Observation(random.randint(0, 50))]

queue_gauge = meter.create_observable_gauge(
    name="frontend.queue.size",
    description="Current queue size",
    unit="items",
    callbacks=[get_queue_size]
)

def get_memory_usage():
    """Simulated memory usage percentage"""
    return [metrics.Observation(random.uniform(45.0, 85.0))]

memory_gauge = meter.create_observable_gauge(
    name="frontend.memory.usage",
    description="Memory usage percentage",
    unit="percent",
    callbacks=[get_memory_usage]
)

app = Flask(__name__)

# Backend service URL
BACKEND_URL = "http://demo-backend:5000"

# Auto-traffic generation settings
AUTO_TRAFFIC_ENABLED = os.getenv('AUTO_TRAFFIC', 'true').lower() == 'true'
TRAFFIC_INTERVAL_MIN = int(os.getenv('TRAFFIC_INTERVAL_MIN', '1'))  # seconds
TRAFFIC_INTERVAL_MAX = int(os.getenv('TRAFFIC_INTERVAL_MAX', '1'))  # seconds

def generate_auto_traffic():
    """Background thread that generates automatic traffic for demo purposes"""
    logger.info(f"Auto-traffic generation started (interval: {TRAFFIC_INTERVAL_MIN}-{TRAFFIC_INTERVAL_MAX}s)")
    
    # Wait a bit for the app to fully start
    time.sleep(10)
    
    endpoints = ['/hello', '/calculate', '/process-order', '/error']
    weights = [25, 25, 40, 10]  # 40% complex orders, 25% calc, 25% hello, 10% error
    
    while True:
        try:
            # Choose an endpoint based on weights
            endpoint = random.choices(endpoints, weights=weights, k=1)[0]
            
            logger.info(f"Auto-traffic: calling {endpoint}")
            
            # Make internal request
            try:
                response = requests.get(f"http://localhost:5000{endpoint}", timeout=10)
                logger.info(f"Auto-traffic: {endpoint} -> {response.status_code}")
            except Exception as e:
                logger.warning(f"Auto-traffic request failed: {e}")
            
            # Random delay between requests
            delay = random.uniform(TRAFFIC_INTERVAL_MIN, TRAFFIC_INTERVAL_MAX)
            time.sleep(delay)
            
        except Exception as e:
            logger.error(f"Auto-traffic generation error: {e}")
            time.sleep(5)

@app.route('/')
def home():
    # Record metrics
    request_counter.add(1, {"endpoint": "home", "method": "GET"})
    active_requests.add(1)
    
    start_time = time.time()
    
    logger.info("Home endpoint called")
    result = jsonify({
        "message": "TinyOlly Demo App",
        "endpoints": ["/", "/hello", "/calculate", "/process-order", "/error"],
        "auto_traffic": "enabled" if AUTO_TRAFFIC_ENABLED else "disabled"
    })
    
    # Record response time
    duration_ms = (time.time() - start_time) * 1000
    response_time_histogram.record(duration_ms, {"endpoint": "home"})
    active_requests.add(-1)
    
    return result

@app.route('/hello')
def hello():
    # Record metrics
    request_counter.add(1, {"endpoint": "hello", "method": "GET"})
    active_requests.add(1)
    
    start_time = time.time()
    
    name = random.choice(["Alice", "Bob", "Charlie", "Diana"])
    logger.info(f"Greeting user: {name}")
    
    # Simulate some work
    work_duration = random.uniform(0.1, 0.5)
    time.sleep(work_duration)
    
    logger.info(f"Completed greeting for {name}")
    
    result = jsonify({
        "message": f"Hello, {name}!",
        "timestamp": time.time()
    })
    
    # Record response time
    duration_ms = (time.time() - start_time) * 1000
    response_time_histogram.record(duration_ms, {"endpoint": "hello"})
    active_requests.add(-1)
    
    return result

@app.route('/calculate')
def calculate():
    # Record metrics
    request_counter.add(1, {"endpoint": "calculate", "method": "GET"})
    active_requests.add(1)
    
    start_time = time.time()
    
    logger.info("Starting calculation")
    
    # Simulate complex calculation
    a = random.randint(1, 100)
    b = random.randint(1, 100)
    
    logger.info(f"Calculating {a} + {b}")
    calc_duration = random.uniform(0.2, 0.8)
    time.sleep(calc_duration)
    result = a + b
    
    logger.info(f"Calculation complete: {result}")
    
    return jsonify({
        "operation": "addition",
        "a": a,
        "b": b,
        "result": result
    })

@app.route('/process-order')
def process_order():
    """
    Complex endpoint showing distributed tracing across services.
    All spans are automatically created by OpenTelemetry instrumentation!
    """
    # Record metrics
    request_counter.add(1, {"endpoint": "process_order", "method": "GET"})
    active_requests.add(1)
    
    start_time = time.time()
    
    # Generate order details
    order_id = random.randint(1000, 9999)
    customer_id = random.randint(100, 999)
    item_count = random.randint(1, 5)
    base_price = random.uniform(10.0, 100.0) * item_count
    
    log_json('info', "Processing order", 
             order_id=order_id, 
             customer_id=customer_id, 
             item_count=item_count,
             operation="order_start")
    
    # Step 1: Validate request (local work)
    log_json('info', "Validating order", order_id=order_id, step="validation")
    time.sleep(random.uniform(0.02, 0.05))
    log_json('info', "Order validation successful", order_id=order_id, step="validation")
    
    try:
        # Step 2: Check inventory via backend service
        # OpenTelemetry auto-instrumentation automatically creates distributed trace!
        log_json('info', "Checking inventory", item_count=item_count, step="inventory_check")
        inventory_response = requests.post(
            f"{BACKEND_URL}/check-inventory",
            json={"items": item_count},
            timeout=5
        )
        inventory_data = inventory_response.json()
        in_stock = inventory_data.get('available', True)
        
        if not in_stock:
            log_json('warning', "Items not available", 
                    item_count=item_count, 
                    reason="out_of_stock")
            return jsonify({
                "status": "failed",
                "order_id": order_id,
                "message": "Items out of stock"
            }), 409
        
        log_json('info', "Inventory check complete", 
                item_count=item_count, 
                status="available")
        
        # Step 3: Calculate pricing via backend service
        log_json('info', "Calculating order pricing", 
                item_count=item_count, 
                base_price=round(base_price, 2))
        pricing_response = requests.post(
            f"{BACKEND_URL}/calculate-price",
            json={"items": item_count, "base_price": base_price},
            timeout=5
        )
        pricing_data = pricing_response.json()
        total_price = pricing_data.get('total', 0)
        
        log_json('info', "Pricing calculation complete", 
                total_price=round(total_price, 2), 
                step="pricing")
        
        # Step 4: Reserve inventory (local work)
        log_json('info', "Reserving inventory", 
                item_count=item_count, 
                step="reservation")
        time.sleep(random.uniform(0.06, 0.1))
        log_json('info', "Inventory reserved", 
                item_count=item_count)
        
        # Step 5: Process payment via backend service
        log_json('info', "Processing payment", 
                amount=round(total_price, 2), 
                step="payment")
        payment_response = requests.post(
            f"{BACKEND_URL}/process-payment",
            json={"amount": total_price},
            timeout=5
        )
        
        if payment_response.status_code == 200:
            payment_data = payment_response.json()
            receipt_id = payment_data.get('receipt_id')
            
            logger.info(f"Payment successful, receipt: {receipt_id}")
            
            # Step 6: Send confirmation (local work)
            logger.info(f"Sending confirmation to customer {customer_id}")
            time.sleep(random.uniform(0.04, 0.08))
            logger.info("Confirmation sent")
            
            logger.info(f"Order {order_id} completed successfully")
            
            # Record successful order metrics
            order_counter.add(1, {"status": "success"})
            order_value_histogram.record(total_price, {"status": "success"})
            duration_ms = (time.time() - start_time) * 1000
            response_time_histogram.record(duration_ms, {"endpoint": "process_order", "status": "success"})
            active_requests.add(-1)
            
            return jsonify({
                "status": "success",
                "order_id": order_id,
                "customer_id": customer_id,
                "items": item_count,
                "total": round(total_price, 2),
                "receipt_id": receipt_id,
                "message": "Order processed successfully"
            })
        else:
            logger.error("Payment declined")
            
            # Record failed order metrics
            order_counter.add(1, {"status": "declined"})
            error_counter.add(1, {"type": "payment_declined"})
            duration_ms = (time.time() - start_time) * 1000
            response_time_histogram.record(duration_ms, {"endpoint": "process_order", "status": "failed"})
            active_requests.add(-1)
            
            return jsonify({
                "status": "failed",
                "order_id": order_id,
                "message": "Payment was declined"
            }), 402
            
    except requests.exceptions.RequestException as e:
        logger.error(f"Backend service error: {str(e)}")
        
        # Record error metrics
        order_counter.add(1, {"status": "error"})
        error_counter.add(1, {"type": "backend_error"})
        duration_ms = (time.time() - start_time) * 1000
        response_time_histogram.record(duration_ms, {"endpoint": "process_order", "status": "error"})
        active_requests.add(-1)
        
        return jsonify({
            "status": "error",
            "order_id": order_id,
            "message": "Service temporarily unavailable"
        }), 503

@app.route('/error')
def error():
    # Record metrics
    request_counter.add(1, {"endpoint": "error", "method": "GET"})
    active_requests.add(1)
    error_counter.add(1, {"type": "intentional"})
    
    logger.error("Error endpoint called - simulating failure")
    
    # Randomly decide what kind of error
    if random.random() > 0.5:
        logger.error("Raising ValueError")
        active_requests.add(-1)
        raise ValueError("Simulated error for testing")
    else:
        logger.warning("Returning error response")
        active_requests.add(-1)
        return jsonify({"error": "Something went wrong"}), 500

if __name__ == '__main__':
    print("=" * 60)
    print("Starting demo frontend application")
    print(f"AUTO_TRAFFIC_ENABLED: {AUTO_TRAFFIC_ENABLED}")
    print("=" * 60)
    logger.info("Starting demo frontend application")
    
    # Start auto-traffic generation in background thread
    if AUTO_TRAFFIC_ENABLED:
        traffic_thread = threading.Thread(target=generate_auto_traffic, daemon=True)
        traffic_thread.start()
        print("✓ Auto-traffic generation thread started")
        logger.info("Auto-traffic generation thread started")
    else:
        print("✗ Auto-traffic generation disabled")
        logger.info("Auto-traffic generation disabled")
    
    app.run(host='0.0.0.0', port=5000)
